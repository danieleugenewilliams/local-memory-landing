# Local Memory Landing Page Copy

## Hero Section

### Main Headline
**The AI Memory System That Actually Works**

### Subheading  
**Enterprise performance, developer price. 5-8x faster vector search with native MCP integration.**

### Key Benefits (3-column layout)
```
âš¡ 11ms Response Times          ğŸ”§ 26+ Native MCP Tools         ğŸŒ Universal Compatibility
Production-grade performance   Appear directly in Claude       Works with any AI platform
5-8x faster than alternatives  Desktop & Code                  MCP + REST API support
```

### Primary CTA
```
[ğŸš€ Get Early Access - $29] [ğŸ“Š View Benchmarks]
```

### Supporting Text
*One-time purchase â€¢ Zero dependencies â€¢ Works offline â€¢ 2-minute setup*

---

## Performance Leadership Section

### Headline
**Enterprise Performance You Can Actually Measure**

### Performance Grid
```
| Metric              | Before    | After     | Improvement        |
|---------------------|-----------|-----------|-------------------|
| Vector Search       | 50-100ms  | 11-15ms   | ğŸš€ 5-8x FASTER    |
| Full-text Search    | 30-50ms   | 20ms      | ğŸš€ 2-3x FASTER    |
| Tag Search          | 25ms      | 12ms      | ğŸš€ 2x FASTER      |
| API Response        | 30ms      | 15-20ms   | ğŸš€ 1.5-2x FASTER  |
```

### Supporting Copy
"Engineered for **production-grade performance** with Â±1ms consistency. While other memory systems struggle with basic queries, local-memory handles high-volume workloads with enterprise reliability."

### Technical Badge
*âœ… Performance Grade: A+ â€¢ Ready for production workloads*

---

## Universal Compatibility Section

### Headline
**Works With Every AI Platform (Seriously)**

### Platform Grid
```
ğŸ–¥ï¸ Claude Desktop          ğŸ’» Claude Code             ğŸŒ Any AI Platform
Native MCP Integration     MCP + REST API Support     Universal REST API
26+ tools appear directly   Terminal & web integration  OpenCode, ChatGPT, custom agents
```

### Code Examples Tabs

#### Tab 1: Claude Desktop (MCP)
```json
{
  "mcpServers": {
    "local-memory": {
      "command": "/usr/local/bin/local-memory",
      "args": []
    }
  }
}
```

#### Tab 2: Claude Code (MCP)
```bash
claude mcp add local-memory /path/to/local-memory-mcp
```

#### Tab 3: Universal REST API
```javascript
// Works with any AI platform
const response = await fetch('http://localhost:3002/memories/search', {
  method: 'POST',
  body: JSON.stringify({
    query: "authentication patterns",
    use_ai: true,
    limit: 5
  })
});
```

### Supporting Copy
"**Future-proof architecture.** Native MCP integration for modern AI agents, universal REST API for everything else. The only memory system designed for both protocols."

---

## Developer-First Design Section

### Headline
**Built by Developers, for Developers**

### Feature Grid (3 columns)
```
ğŸ—ï¸ Zero Dependencies           âš¡ Memory Efficient         ğŸ› ï¸ Production Ready
Single binary                 16MB RAM usage              SQLite + Qdrant support
No Node.js, Python, Docker    vs 200MB+ alternatives     Health monitoring included
Cross-platform support        Automatic DB creation       Graceful error handling
```

### Quick Start
```
# Download, extract, run
local-memory start

# 2 minutes to full AI memory
âœ… Database created automatically
âœ… Vector search optimized  
âœ… 26+ MCP tools ready
âœ… REST API listening on :3002
```

### Developer Benefits
- **Persistent Expertise**: AI agents remember your codebase, patterns, and solutions
- **Cross-Session Learning**: Knowledge builds up over time, not lost between conversations  
- **Smart Context Retrieval**: Vector search finds relevant context automatically
- **Team Knowledge Base**: Shared memory across your development team

---

## Pricing Section

### Headline
**Premium Performance, Indie Price**

### Pricing Card
```
ğŸ¯ Early Access Special
 
$29 (normally $49)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ“ Complete local-memory system
âœ“ All 26+ MCP tools included
âœ“ Unlimited usage forever
âœ“ Priority email support
âœ“ Future updates included

[ğŸš€ Get Early Access Now]

â° Limited time: First 1000 developers
ğŸ’° One-time purchase, no subscriptions
ğŸ $10 credit for each referral
```

### Value Comparison
*"Costs less than 2 hours of development time. Saves hundreds of hours of re-explaining context to AI agents."*

### FAQ Preview
```
â“ What if I don't like it?
ğŸ’¡ 30-day money-back guarantee

â“ Do I need anything else installed?  
ğŸ’¡ Only Ollama for AI features (optional)

â“ Does it work offline?
ğŸ’¡ Completely offline after setup
```

---

## Social Proof Section

### Headline
**Performance That Speaks for Itself**

### Benchmark Highlight
```
ğŸ† BENCHMARK RESULTS
"Outstanding performance improvements across all metrics"
- 5-8x faster vector search
- Enterprise-grade consistency (Â±1ms variation)
- Ready for high-volume production workloads
```

### Technical Validation
*"Performance-optimized architecture delivers exceptional results. These benchmark numbers outclass existing solutions while maintaining full compatibility."*

### Community Badge
*ğŸ¥‡ **Founding Developer Program** - First 100 customers get priority support and exclusive updates*

---

## Call-to-Action Section

### Headline
**Join the Memory Revolution**

### Final Pitch
"Stop re-explaining your codebase to AI agents. Give them persistent memory with enterprise performance."

### Dual CTA
```
[ğŸš€ Get Early Access - $29]    [ğŸ“– Read Documentation]
40% off â€¢ Limited time          Technical specs & setup guide
```

### Trust Signals
```
âœ… 30-day money-back guarantee
âœ… Secure one-time payment via Stripe  
âœ… Instant download after purchase
âœ… Email support included
```

### Final Hook
*"The only AI memory system with native MCP integration AND universal REST API. Future-proof your AI workflow today."*

---

## Technical Specifications (Expandable Section)

### System Requirements
- **Platforms**: macOS (Intel/Apple Silicon), Linux, Windows
- **Memory**: 16MB typical usage (8GB+ recommended for Ollama)
- **Storage**: 50MB binary + vector database (grows with usage)
- **Network**: Only for initial Ollama model download (optional)

### Technical Features
- **Protocols**: MCP (Model Context Protocol) + REST API
- **Storage**: SQLite database with optional Qdrant vector support
- **Search**: Vector similarity + full-text + semantic AI search
- **Performance**: Sub-20ms response times, Â±1ms consistency
- **Integration**: 26+ MCP tools, 20+ REST endpoints

### Architecture Benefits
- **No Dependencies**: Single binary, no runtime requirements
- **Offline Capable**: Works completely offline after setup
- **Memory Efficient**: 16MB vs 200MB+ Node.js alternatives
- **Production Ready**: Health monitoring, graceful error handling